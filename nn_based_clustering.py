# -*- coding: utf-8 -*-
"""NN_based_clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x6iimrSbuevECJmHbK8VmSYrlosTAJSU
"""

!pip install datasets
!pip install --upgrade pip
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
!pip install nvidia-cublas-cu12==12.4.5.8

import torch
import torch . nn as nn
import torch . optim as optim
from torch . utils . data import DataLoader
import torchvision . transforms as transforms
import torchvision . datasets as datasets
from torch.utils.data import Dataset
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModel
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import seaborn as sns
import numpy as np

#Loading dataset

ds = load_dataset("Tohrumi/glue_sst2_10k", split="train")
texts = ds['sentence']

#Text Preprocessing and Embedding using BERT
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
bert_model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model.to(device)

def encode_sentences(texts, batch_size=32):
    bert_model.eval()
    embeddings = []
    with torch.no_grad():
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            encoded = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)
            output = bert_model(**encoded)
            att_mask = encoded['attention_mask']
            last_hidden = output.last_hidden_state
            input_mask_expanded = att_mask.unsqueeze(-1).expand(last_hidden.size()).float()
            pooled = torch.sum(last_hidden * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)
            embeddings.append(pooled.cpu())
    return torch.cat(embeddings)

sentence_embeddings = encode_sentences(texts)

# Define the Neural Network (Autoencoder Style Encoder)
class SentenceMLP(nn.Module):
    def __init__(self, input_dim=384, hidden_dim=128, latent_dim=64):
        super(SentenceMLP, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, latent_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )

    def forward(self, x):
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed, latent

# Set Hyperparameters
input_dim = sentence_embeddings.shape[1]
hidden_dim = 128
latent_dim = 64
learning_rate = 1e-3
batch_size = 64
epochs = 10

# Dataset and Dataloader
class EmbeddingDataset(Dataset):
    def __init__(self, embeddings):
        self.embeddings = embeddings

    def __len__(self):
        return len(self.embeddings)

    def __getitem__(self, idx):
        return self.embeddings[idx]

embedding_dataset = EmbeddingDataset(sentence_embeddings)
embedding_loader = DataLoader(embedding_dataset, batch_size=batch_size, shuffle=True)

# Initialize Model, Loss Function, Optimizer
model = SentenceMLP(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=latent_dim).to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

#Training Loop
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in embedding_loader:
        batch = batch.to(device)
        reconstructed, _ = model(batch)
        loss = criterion(reconstructed, batch)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}")

# Generate Latent Embeddings
model.eval()
with torch.no_grad():
    _, latent_embeddings = model(sentence_embeddings.to(device))
latent_embeddings = latent_embeddings.cpu().numpy()

# Apply Clustering (KMeans)
n_clusters = 5
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
cluster_labels = kmeans.fit_predict(latent_embeddings)

# Evaluation Metrics
sil_score = silhouette_score(latent_embeddings, cluster_labels)
db_score = davies_bouldin_score(latent_embeddings, cluster_labels)
ch_score = calinski_harabasz_score(latent_embeddings, cluster_labels)

print(f"Silhouette Score: {sil_score:.4f}")
print(f"Davies-Bouldin Index: {db_score:.4f}")
print(f"Calinski-Harabasz Index: {ch_score:.4f}")

# Visualization
tsne = TSNE(n_components=2, random_state=42)
tsne_results = tsne.fit_transform(latent_embeddings)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], hue=cluster_labels, palette="Set2", s=60)
plt.title("t-SNE Visualization of Clusters")
plt.show()